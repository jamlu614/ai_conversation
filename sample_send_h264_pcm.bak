//  Agora RTC/MEDIA SDK
//
//  Created by Jay Zhang in 2020-04.
//  Copyright (c) 2020 Agora.io. All rights reserved.
//

// video
//    ******************         --------         *************         ------------       *********        **********         ************       ------------        ***********       --------
//   {SDK::capture video}  ==>  |raw data|  ==>  {SDK::encode B}  ==>  |encoded data| ==> {SDK::send}  ==> {AGORA::VOS}  ==>  {SDK::receive} ==> |encoded data|  ==> {SDK::decode} ==> |raw data|
//    ******************         --------         *************         ------------       *********        **********         ************       ------------        ***********       --------
//                                                                                   sample send h264(this sample)                              sample receive h264

// This sample will show how to use the SDK to send the encoded_Video to the Agora_channel
// As a user,you should papera the encoded_Video and create the Agora_service,Agora_connection, Agora_EncodedImage_sender and Agora_local_video_track
// You should parse the encoded_Video and send to sdk one frame by one frame.(by use the AGORA_API: Sender->sendEncodedVideoImage())
// The class HelperH264FileParser is a common_helper class to parse the h264 video
// And all Agora necessary Classes builded in main() function
// Last, the sendVideoThread call Sender->sendEncodedVideoImage() to send the encoded videoFrame

// The sdk also provide lots of call_back functions to help user get the network states , local states and  peer states
// The callback functions can be found in **observer , you should register the observer first.

// the SDKapi call flows:
// service = createAndInitAgoraService()
//     connection = service->createRtcConnection()
//         connection->registerObserver()
//             connection->connect()
//         factory = service->createMediaNodeFactory()
//             VideoSender = factory->createVideoEncodedImageSender();
//                 VideoTrack = service->createCustomVideoTrack()
//      connection->getLocalUser()->publishAudio(VideoTrack);
//                 Sender->sendEncodedVideoImage()

// audio
//    ******************         --------         *************         ------------       *********        **********         ************       ------------        ***********       --------
//   {SDK::capture audio}  ==>  |raw data|  ==>  {SDK::encode B}  ==>  |encoded data| ==> {SDK::send}  ==> {AGORA::VOS}  ==>  {SDK::receive} ==> |encoded data|  ==> {SDK::decode} ==> |raw data|
//    ******************         --------         *************         ------------       *********        **********         ************       ------------        ***********       --------
//                         sample send pcm(this sample)                sample send opus                                                                                            sample receive pcm

// This sample will show how to use the SDK to send the raw AudioData(pcm) to the Agora_channel
// As a user,you should papera the audio and create the Agora_service,Agora_connection, Agora_audio_pcm_sender and Agora_local_audio_track
// You should parse the audio and send to sdk one frame by one frame.(by use the AGORA_API: Sender->sendAudioPcmData())
// And all Agora necessary Classes builded in main() function
// Last, the sendAudioThread call Sender->sendAudioPcmData() to send the audioFrame

// The sdk also provide lots of call_back functions to help user get the network states , local states and  peer states
// The callback functions can be found in **observer , you should register the observer first.

// the SDKapi call flows:
// service = createAndInitAgoraService()
//     connection = service->createRtcConnection()
//         connection->registerObserver()
//         connection->connect()
//         factory = service->createMediaNodeFactory()
//             AudioSender = factory->createAudioPcmDataSender();
//                 AudioTrack = service->createCustomAudioTrack();
//      connection->getLocalUser()->publishAudio(audioTrack);
//                 Sender->sendAudioPcmData()

// The destruct order of all the class can be find in the main function end.

// Wish you have a great experience with Agora_SDK!

#include <csignal>
#include <cstring>
#include <sstream>
#include <string>
#include <thread>

#include "IAgoraService.h"
#include "NGIAgoraRtcConnection.h"
#include "common/helper.h"
#include "common/log.h"
#include "common/opt_parser.h"
#include "common/sample_common.h"
#include "common/sample_connection_observer.h"
#include "common/sample_local_user_observer.h"

#include "NGIAgoraAudioTrack.h"
#include "NGIAgoraLocalUser.h"
#include "NGIAgoraMediaNodeFactory.h"

#include "NGIAgoraMediaNode.h"
#include "NGIAgoraVideoTrack.h"

#include "helper_h264_parser.h"

#include "video_encode_camera2h264.hpp"
#include <queue>
#include <curl/curl.h>
#include <mutex>
#include <iostream>
#include <fstream>
#include "RtcTokenBuilder2.h"

#include <nlohmann/json.hpp>
#include <mosquitto.h>
#include <ini.h>
#include <libgen.h> // for dirname
extern "C"
{
#include <audio_espeak_play.h>
#include "sample_send_h264_pcm.h"
#include <speex/speex_echo.h>
#include <speex/speex_preprocess.h>
}

#define DEFAULT_CONNECT_TIMEOUT_MS (3000)
#define DEFAULT_SAMPLE_RATE (16000)
#define DEFAULT_NUM_OF_CHANNELS (1)
#define DEFAULT_FRAME_RATE (30)
// #define DEFAULT_AUDIO_FILE "../send_audio_16k_1ch.pcm"
#define DEFAULT_AUDIO_FILE "../send_audio_16k_1ch.pcm"
#define DEFAULT_VIDEO_FILE "../send_video.h264"
using namespace std;
using json = nlohmann::json;

CURL *curl;
CURLcode res;
std::string readBuffer;
static std::queue<std::shared_ptr<HelperH264Frame>> micAudioQueue;
static bool exitFlag = false;
static bool captureAudioFlag = true;
static bool playAudioFlag = true;
std::thread playAudioThread;
// const char *app_id = "4dfbb27cc2a64ac9b43135be289a858e";
// const char *app_certificate = "0abbf21056df4efabd4b1a66528f75c1";
std::string agent_id;
Configuration config;

// std::ofstream micAudioFile("mic2.pcm", std::ios::binary);
// std::ofstream playAudioFile("speak.pcm", std::ios::binary);
// std::ofstream cleanAudioFile("clean.pcm", std::ios::binary);

void publishMessage(mosquitto *mosq, const char *message);

class PcmFrameObserver : public agora::media::IAudioFrameObserverBase
{
public:
  PcmFrameObserver(const std::string &outputFilePath)
      : outputFilePath_(outputFilePath),
        pcmFile_(nullptr),
        fileCount(0),
        fileSize_(0) {}

  bool onPlaybackAudioFrame(const char *channelId, AudioFrame &audioFrame) override { return true; };

  bool onRecordAudioFrame(const char *channelId, AudioFrame &audioFrame) override { return true; };

  bool onMixedAudioFrame(const char *channelId, AudioFrame &audioFrame) override { return true; };

  bool onEarMonitoringAudioFrame(AudioFrame &audioFrame) { return true; };

  bool onPlaybackAudioFrameBeforeMixing(const char *channelId, agora::media::base::user_id_t userId, AudioFrame &audioFrame) override;

  int getObservedAudioFramePosition() override { return 0; };

  AudioParams getPlaybackAudioParams() override { return AudioParams(); };

  AudioParams getRecordAudioParams() override { return AudioParams(); };

  AudioParams getMixedAudioParams() override { return AudioParams(); };

  AudioParams getEarMonitoringAudioParams() override { return AudioParams(); };

private:
  std::string outputFilePath_;
  FILE *pcmFile_;
  int fileCount;
  int fileSize_;
};

class H264FrameReceiver : public agora::media::IVideoEncodedFrameObserver
{
public:
  H264FrameReceiver(const std::string &outputFilePath)
      : outputFilePath_(outputFilePath),
        h264File_(nullptr),
        fileCount(0),
        fileSize_(0) {}

  bool onEncodedVideoFrameReceived(agora::rtc::uid_t uid, const uint8_t *imageBuffer, size_t length,
                                   const agora::rtc::EncodedVideoFrameInfo &videoEncodedFrameInfo) override;

private:
  std::string outputFilePath_;
  FILE *h264File_;
  int fileCount;
  int fileSize_;
};

static std::queue<std::shared_ptr<HelperH264Frame>> videoQueue;
void videoCallback(u_int8_t *data, int len, bool isKeyFrame)
{
  std::shared_ptr<HelperH264Frame> h264Frame = std::make_shared<HelperH264Frame>();
  auto *h264FrameP = h264Frame.get();
  h264FrameP->buffer = std::unique_ptr<uint8_t[]>(data);
  h264FrameP->bufferLen = len;
  h264FrameP->isKeyFrame = isKeyFrame;
  videoQueue.push(h264Frame);
}

void audioCallback(u_int8_t *data, int len)
{

  std::shared_ptr<HelperH264Frame> h264Frame = std::make_shared<HelperH264Frame>();
  auto *h264FrameP = h264Frame.get();
  h264FrameP->buffer = std::unique_ptr<uint8_t[]>((uint8_t *)data);
  h264FrameP->bufferLen = len;
  micAudioQueue.push(h264Frame);
}

bool PcmFrameObserver::onPlaybackAudioFrameBeforeMixing(const char *channelId, agora::media::base::user_id_t userId, AudioFrame &audioFrame)
{
  size_t audio_size = audioFrame.samplesPerChannel * audioFrame.channels * sizeof(int16_t);
  uint8_t *data = (uint8_t *)audioFrame.buffer;
  int channel = audioFrame.samplesPerChannel;
  int samples = audioFrame.samplesPerSec;
  // printf("samples:%d\n",samples);
  // printf("channels:%d\n",audioFrame.channels );
  // printf("收到音频数据\n");
  // playAudioFile.write(reinterpret_cast<const char *>(data), audio_size);
  pushPCM(data, audio_size);
  return true;
}

static uint8_t frameBuf[DEFAULT_NUM_OF_CHANNELS * sizeof(int16_t) * DEFAULT_SAMPLE_RATE / 100];
int curSampleSize = 0;

static void sendOnePcmFrame(const SampleOptions &options,
                            agora::agora_refptr<agora::rtc::IAudioPcmDataSender> audioFrameSender)
{
  static FILE *file = nullptr;
  const char *fileName = options.audioFile.c_str();

  // Calculate byte size for 10ms audio samples
  int sampleSize = sizeof(int16_t) * options.audio.numOfChannels;
  int samplesPer10ms = options.audio.sampleRate / 100;
  int sendBytes = sampleSize * samplesPer10ms;

  uint8_t *frame = nullptr;
  int nextOffset = 0;
  int offset = 0;
  while (curSampleSize < sendBytes && !exitFlag)
  {
    if (!micAudioQueue.empty() && captureAudioFlag)
    {
      int len = 0;
      frame = micAudioQueue.front().get()->buffer.get();
      len = micAudioQueue.front().get()->bufferLen;
      if (curSampleSize + len <= sendBytes)
      {
        memcpy(frameBuf + curSampleSize, frame, len);
        // printf("祯长度:%d\n", len);
        // printf("当前长度:%d\n", curSampleSize);
        // printf("拷贝长度:%d\n", len);
      }
      else
      {
        offset = sendBytes - curSampleSize;
        nextOffset = len - offset;
        // printf("nextOffset:%d\n", nextOffset);
        // printf("offset:%d\n", offset);
        memcpy(frameBuf + curSampleSize, frame, offset);
        // printf("祯长度:%d\n", len);
        // printf("当前长度:%d\n", curSampleSize);
        // printf("拷贝长度:%d\n", offset);
        // printf("一祯音频数据\n");
      }
      curSampleSize += len;
      micAudioQueue.pop();
    }
    else
    {
      usleep(10 * 1000);
    }
  }
  // micAudioFile.write(reinterpret_cast<const char *>(frameBuf), sendBytes);
  // printf("发送音频数据\n");
  int ret = 0;
  ret = audioFrameSender->sendAudioPcmData(
      reinterpret_cast<const char *>(frameBuf), 0, samplesPer10ms, agora::rtc::TWO_BYTES_PER_SAMPLE,
      options.audio.numOfChannels, options.audio.sampleRate);

  if (ret < 0)
  {
    AG_LOG(ERROR, "Failed to send audio frame!");
    return;
  }

  memset(frameBuf, 0, sendBytes);
  if (nextOffset > 0)
  {
    memcpy(frameBuf, frame + offset, nextOffset);
    // printf("剩余拷贝长度:%d\n", nextOffset);
    curSampleSize = nextOffset;
  }
  else
  {
    curSampleSize = 0;
  }

  //--------------------------------------------------------------------------
  // if (!audioQueue.empty())
  // {
  //   frame = audioQueue.front().get()->buffer.get();
  //   int len = audioQueue.front().get()->bufferLen;
  //   outputFile.write(reinterpret_cast<const char *>(frame), len);
  //   audioQueue.pop();
  //   // int ret = audioFrameSender->sendAudioPcmData(frameBuf, 0, samplesPer10ms, agora::rtc::TWO_BYTES_PER_SAMPLE,
  //   //                                              options.audio.numOfChannels,
  //   //                                              options.audio.sampleRate);

  //   // if (ret < 0)
  //   // {
  //   //   AG_LOG(ERROR, "Failed to send audio frame!");
  //   // }
  // }
}

static void sendOneH264Frame(
    int frameRate, std::shared_ptr<HelperH264Frame> h264Frame,
    agora::agora_refptr<agora::rtc::IVideoEncodedImageSender> videoH264FrameSender)
{
  agora::rtc::EncodedVideoFrameInfo videoEncodedFrameInfo;
  videoEncodedFrameInfo.rotation = agora::rtc::VIDEO_ORIENTATION_0;
  videoEncodedFrameInfo.codecType = agora::rtc::VIDEO_CODEC_H264;
  videoEncodedFrameInfo.framesPerSecond = frameRate;
  videoEncodedFrameInfo.frameType =
      (h264Frame.get()->isKeyFrame ? agora::rtc::VIDEO_FRAME_TYPE::VIDEO_FRAME_TYPE_KEY_FRAME
                                   : agora::rtc::VIDEO_FRAME_TYPE::VIDEO_FRAME_TYPE_DELTA_FRAME);

  // AG_LOG(DEBUG, "sendEncodedVideoImage, buffer %p, len %d, frameType %d",
  //        reinterpret_cast<uint8_t *>(h264Frame.get()->buffer.get()), h264Frame.get()->bufferLen,
  //        videoEncodedFrameInfo.frameType);

  videoH264FrameSender->sendEncodedVideoImage(
      reinterpret_cast<uint8_t *>(h264Frame.get()->buffer.get()), h264Frame.get()->bufferLen,
      videoEncodedFrameInfo);
}

static void SampleSendAudioTask(
    const SampleOptions &options,
    agora::agora_refptr<agora::rtc::IAudioPcmDataSender> audioFrameSender, bool &exitFlag)
{
  // Currently only 10 ms PCM frame is supported. So PCM frames are sent at 10 ms interval
  PacerInfo pacer = {0, 10, 0, std::chrono::steady_clock::now()};

  // 打开输出文件
  // if (!micAudioFile.is_open())
  // {
  //   printf("Could not open output file.");
  //   return;
  // }
  // if (!playAudioFile.is_open())
  // {
  //   printf("Could not open output file.");
  //   return;
  // }

  while (!exitFlag)
  {
    // if (openSpeakFlag)
    sendOnePcmFrame(options, audioFrameSender);
    waitBeforeNextSend(pacer); // sleep for a while before sending next frame
  }
  // micAudioFile.close();
  // playAudioFile.close();
  // cleanAudioFile.close();
}

static void SampleSendVideoH264Task(
    const SampleOptions &options,
    agora::agora_refptr<agora::rtc::IVideoEncodedImageSender> videoH264FrameSender,
    bool &exitFlag)
{
  // std::unique_ptr<HelperH264FileParser> h264FileParser(
  //     new HelperH264FileParser(options.videoFile.c_str()));
  // h264FileParser->initialize();

  // Calculate send interval based on frame rate. H264 frames are sent at this interval
  PacerInfo pacer = {0, 1000 / options.video.frameRate, 0, std::chrono::steady_clock::now()};

  while (!exitFlag)
  {
    // if (auto h264Frame = h264FileParser->getH264Frame()) {
    if (!videoQueue.empty())
    {
      auto h264Frame = videoQueue.front();
      videoQueue.pop();
      sendOneH264Frame(options.video.frameRate, h264Frame, videoH264FrameSender);
      waitBeforeNextSend(pacer); // sleep for a while before sending next frame
    }
    else
    {
      usleep(1 * 1000);
    }
    // }
  };
}

static void SignalHandler(int sigNo)
{
  exitFlag = true;
}

// 回调函数，用于处理服务器响应的数据
size_t WriteCallback(void *contents, size_t size, size_t nmemb, std::string *userp)
{
  size_t totalSize = size * nmemb;
  userp->append((char *)contents, totalSize);
  return totalSize;
}

using namespace agora::tools;

void connect_callback(struct mosquitto *mosq, void *obj, int result)
{
  if (!result)
  {
    mosquitto_subscribe(mosq, NULL, "wakeup/text", 1);
    mosquitto_subscribe(mosq, NULL, "wakeup/enable", 1);
  }
}

void message_callback(struct mosquitto *mosq, void *obj, const struct mosquitto_message *msg)
{
  std::cout << "Received: " << msg->topic << " -> " << (char *)msg->payload << std::endl;
  if (strcmp(msg->topic, "wakeup/enable") == 0)
  {
    // 清空采集音队列
    while (!micAudioQueue.empty())
      micAudioQueue.pop();
    // 1 离线语音、2、在线语音 3、停止智能体播放
    if (strcmp((char *)msg->payload, "1") == 0)
    {
      captureAudioFlag = false;
      if (!playAudioFlag)
      {
        while (!micAudioQueue.empty())
          micAudioQueue.pop();
        playAudioFlag = true;
        usleep(500 * 1000);
        playAudioThread = std::thread(startPlayAudio, DEFAULT_NUM_OF_CHANNELS, DEFAULT_SAMPLE_RATE, std::ref(exitFlag), std::ref(playAudioFlag));
      }
    }
    else if (strcmp((char *)msg->payload, "2") == 0)
    {
      captureAudioFlag = true;
      if (!playAudioFlag)
      {
        while (!micAudioQueue.empty())
          micAudioQueue.pop();
        playAudioFlag = true;
        usleep(500 * 1000);
        playAudioThread = std::thread(startPlayAudio, DEFAULT_NUM_OF_CHANNELS, DEFAULT_SAMPLE_RATE, std::ref(exitFlag), std::ref(playAudioFlag));
      }
    }
    else if (strcmp((char *)msg->payload, "3") == 0)
    {
      while (!micAudioQueue.empty())
        micAudioQueue.pop();
      playAudioFlag = false;
      if (playAudioThread.joinable())
      {
        playAudioThread.join();
        printf("关闭播放线程.\n");
      }
    }
    return;
  }
  if (strcmp(msg->topic, "wakeup/text") == 0 && agent_id.length() > 0)
  {

    // audio_espeak_play(VOICES_WITH_MAN_CN, (char *)msg->payload);
    // // audio_espeak_play(VOICES_WITH_MAN_CN, "你好");
    // return;
    // 初始化CURL会话
    curl = curl_easy_init();
    if (curl)
    {
      string url = "https://api.agora.io/cn/api/conversational-ai-agent/v2/projects/" + string(config.app_id) + "/agents/" + string(agent_id) + "/speak";
      // 设置URL
      curl_easy_setopt(curl, CURLOPT_URL, url.c_str());

      // 设置POST请求类型
      curl_easy_setopt(curl, CURLOPT_POST, 1L);

      // 设置POST参数，这里使用一个结构体数组模拟JSON数据，实际应用中可以根据需要修改为具体的字符串格式
      struct curl_slist *headers = NULL;
      headers = curl_slist_append(headers, "Content-Type: application/json"); // 设置头部信息
      headers = curl_slist_append(headers, string("Authorization: Basic " + string(config.authorization)).c_str());
      curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers); // 应用头部信息

      std::string postData = R"({
        "text": ")" + std::string((char *)msg->payload) +
                             R"(",
        "priority": "INTERRUPT",
        "interruptable": true
      })";

      curl_easy_setopt(curl, CURLOPT_POSTFIELDS, postData.c_str()); // 设置POST字段数据
      // AG_LOG(INFO, "json:%s", postData.c_str());
      curl_easy_setopt(curl, CURLOPT_POSTFIELDSIZE, postData.length() + 1); // 使用字符串的实际长度

      // 执行请求
      curl_easy_perform(curl);

      // 设置回调函数，用于接收返回的数据
      // curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
      // curl_easy_setopt(curl, CURLOPT_WRITEDATA, &readBuffer); // 将返回的数据传递给readBuffer

      // 执行请求并获取结果
      // res = curl_easy_perform(curl);
      // if (res != CURLE_OK)
      // {
      //   fprintf(stderr, "curl_easy_perform() failed: %s\n", curl_easy_strerror(res));
      // }
      // else
      // {
      //   std::cout << "Response: " << readBuffer << std::endl; // 输出返回的数据
      // }
    }
  }
}

static int handler(void *user, const char *section, const char *name,
                   const char *value)
{
  Configuration *pconfig = (Configuration *)user;

#define MATCH(s, n) strcmp(section, s) == 0 && strcmp(name, n) == 0
  if (MATCH("user", "version"))
  {
    pconfig->version = atoi(value);
  }
  else if (MATCH("user", "app_id"))
  {
    pconfig->app_id = strdup(value);
  }
  else if (MATCH("user", "channel_name"))
  {
    pconfig->channel_name = strdup(value);
  }
  else if (MATCH("user", "app_certificate"))
  {
    pconfig->app_certificate = strdup(value);
  }
  else if (MATCH("user", "authorization"))
  {
    pconfig->authorization = strdup(value);
  }
  else if (MATCH("user", "audio_dev"))
  {
    pconfig->audio_dev = strdup(value);
  }
  else
  {
    return 0; /* unknown section/name, error */
  }
  return 1;
}

std::string get_executable_path()
{
  char buf[PATH_MAX];
  ssize_t len = readlink("/proc/self/exe", buf, sizeof(buf) - 1);
  if (len != -1)
  {
    buf[len] = '\0';
    return std::string(buf);
  }
  else
  {
    perror("readlink");
    return "";
  }
}

std::string get_executable_directory()
{
  std::string path = get_executable_path();
  if (!path.empty())
  {
    char dir[PATH_MAX];
    // 使用 dirname
    char *result = dirname(dir); // 注意：dirname 会修改 dir 的内容
    if (result != NULL)
    {
      return std::string(result);
    }
  }
  return "";
}

int main(int argc, char *argv[])
{

  try
  {
    // 解析配置文件
    std::string config_path(get_executable_directory() + "/config.ini");
    std::string config_path2(get_executable_directory() + "/../config.ini");
    if (ini_parse(config_path.c_str(), handler, &config) < 0)
    {
      if (ini_parse(config_path2.c_str(), handler, &config) < 0)
      {
        printf("Can't load 'config.ini'\n");
        return 1;
      }
    }
    // --------------------------mqtt创建--------------------------------
    mosquitto_lib_init();
    struct mosquitto *mosq = mosquitto_new("cpp_client", true, nullptr);
    mosquitto_connect_callback_set(mosq, connect_callback);
    mosquitto_message_callback_set(mosq, message_callback);

    if (mosquitto_connect(mosq, "localhost", 1883, 60) != MOSQ_ERR_SUCCESS)
    {
      std::cerr << "Failed to connect!" << std::endl;
      return 1;
    }

    mosquitto_loop_start(mosq);
    //--------------------------mqtt创建结束--------------------------------
    // audio_espeak_dev_init();
    SampleOptions options;
    opt_parser optParser;
    optParser.add_long_opt("token", &options.appId, "The token for authentication / must");
    optParser.add_long_opt("channelId", &options.channelId, "Channel Id / must");
    optParser.add_long_opt("userId", &options.userId, "User Id / default is 0");
    optParser.add_long_opt("remoteUserId", &options.remoteUserId,
                           "The remote user to receive stream from");
    // optParser.add_long_opt("audioFile", &options.audioFile,
    //                        "The audio file in raw PCM format to be sent");
    // optParser.add_long_opt("videoFile", &options.videoFile,
    //                        "The video file in YUV420 format to be sent");
    optParser.add_long_opt("sampleRate", &options.audio.sampleRate,
                           "Sample rate for the PCM file to be sent");
    optParser.add_long_opt("numOfChannels", &options.audio.numOfChannels,
                           "Number of channels for the PCM file to be sent");
    optParser.add_long_opt("fps", &options.video.frameRate,
                           "Target frame rate for sending the video stream");
    optParser.add_long_opt("bwe", &options.video.showBandwidthEstimation,
                           "show or hide bandwidth estimation info");
    optParser.add_long_opt("localIP", &options.localIP,
                           "Local IP");

    // if ((argc <= 1) || !optParser.parse_opts(argc, argv))
    // {
    //   std::ostringstream strStream;
    //   optParser.print_usage(argv[0], strStream);
    //   std::cout << strStream.str() << std::endl;
    //   return -1;
    // }
    optParser.parse_opts(argc, argv);
    // -------------------------------------------------------------------

    std::string channel_name = "test_gac_cname";
    if (options.channelId.empty())
    {
      // AG_LOG(ERROR, "Must provide channelId!");
      // return -1;
      if (strcmp(config.channel_name, "") != 0)
      {
        channel_name = config.channel_name;
      }
      options.channelId = channel_name;
    }

    int expiration_time = 3600 * 24;
    uint32_t uid = 0;
    std::string account = options.userId;
    uint32_t token_expiration_in_seconds = expiration_time;
    uint32_t privilege_expiration_in_seconds = expiration_time;
    uint32_t join_channel_privilege_expiration_in_seconds = expiration_time;
    uint32_t pub_audio_privilege_expiration_in_seconds = expiration_time;
    uint32_t pub_video_privilege_expiration_in_seconds = expiration_time;
    uint32_t pub_data_stream_privilege_expiration_in_seconds = expiration_time;
    std::string token;
    token = RtcTokenBuilder2::BuildTokenWithUserAccount(config.app_id, config.app_certificate, channel_name, account, UserRole::kRolePublisher, token_expiration_in_seconds,
                                                        privilege_expiration_in_seconds);
    // -------------------------------------------------------------------
    if (options.appId.empty())
    {
      // AG_LOG(ERROR, "Must provide appId!");
      // return -1;
      options.appId = token;
    }
    std::cout << "Token With Int Uid:" << options.appId << std::endl;

    std::signal(SIGQUIT, SignalHandler);
    std::signal(SIGABRT, SignalHandler);
    std::signal(SIGINT, SignalHandler);

    // Create Agora service
    auto service = createAndInitAgoraService(false, true, true);
    if (!service)
    {
      AG_LOG(ERROR, "Failed to creating Agora service!");
    }

    // Create Agora connection
    agora::rtc::RtcConnectionConfiguration ccfg;
    ccfg.autoSubscribeAudio = false;
    ccfg.autoSubscribeVideo = false;
    ccfg.clientRoleType = agora::rtc::CLIENT_ROLE_BROADCASTER;
    agora::agora_refptr<agora::rtc::IRtcConnection> connection = service->createRtcConnection(ccfg);
    if (!connection)
    {
      AG_LOG(ERROR, "Failed to creating Agora connection!");
      return -1;
    }

    if (!options.localIP.empty())
    {
      if (setLocalIP(connection, options.localIP))
      {
        AG_LOG(ERROR, "set local IP to %s error!", options.localIP.c_str());
        return -1;
      }
    }

    // Register connection observer to monitor connection event
    auto connObserver = std::make_shared<SampleConnectionObserver>();
    connection->registerObserver(connObserver.get());

    // Register network observer to monitor bandwidth estimation result
    if (options.video.showBandwidthEstimation)
    {
      connection->registerNetworkObserver(connObserver.get());
    }

    // Create local user observer to monitor intra frame request
    auto localUserObserver = std::make_shared<SampleLocalUserObserver>(connection->getLocalUser());

    // Register audio frame observer to receive audio stream
    auto pcmFrameObserver = std::make_shared<PcmFrameObserver>(options.audioFile);
    if (connection->getLocalUser()->setPlaybackAudioFrameBeforeMixingParameters(
            options.audio.numOfChannels, options.audio.sampleRate))
    {
      AG_LOG(ERROR, "Failed to set audio frame parameters!");
      return -1;
    }
    localUserObserver->setAudioFrameObserver(pcmFrameObserver.get());

    // Connect to Agora channel
    if (connection->connect(options.appId.c_str(), options.channelId.c_str(),
                            options.userId.c_str()))
    {
      AG_LOG(ERROR, "Failed to connect to Agora channel!");
      return -1;
    }

    // Create media node factory
    agora::agora_refptr<agora::rtc::IMediaNodeFactory> factory = service->createMediaNodeFactory();
    if (!factory)
    {
      AG_LOG(ERROR, "Failed to create media node factory!");
    }

    // Create audio data sender
    agora::agora_refptr<agora::rtc::IAudioPcmDataSender> audioFrameSender =
        factory->createAudioPcmDataSender();
    if (!audioFrameSender)
    {
      AG_LOG(ERROR, "Failed to create audio data sender!");
      return -1;
    }

    // Create audio track
    agora::agora_refptr<agora::rtc::ILocalAudioTrack> customAudioTrack =
        service->createCustomAudioTrack(audioFrameSender);
    if (!customAudioTrack)
    {
      AG_LOG(ERROR, "Failed to create audio track!");
      return -1;
    }

    // Create video frame sender
    agora::agora_refptr<agora::rtc::IVideoEncodedImageSender> videoFrameSender =
        factory->createVideoEncodedImageSender();
    if (!videoFrameSender)
    {
      AG_LOG(ERROR, "Failed to create video frame sender!");
      return -1;
    }

    agora::rtc::SenderOptions option;
    option.ccMode = agora::rtc::TCcMode::CC_ENABLED;
    // Create video track
    agora::agora_refptr<agora::rtc::ILocalVideoTrack> customVideoTrack =
        service->createCustomVideoTrack(videoFrameSender, option);
    if (!customVideoTrack)
    {
      AG_LOG(ERROR, "Failed to create video track!");
      return -1;
    }

    // Publish audio & video track
    connection->getLocalUser()->publishAudio(customAudioTrack);
    connection->getLocalUser()->publishVideo(customVideoTrack);

    // Wait until connected before sending media stream
    connObserver->waitUntilConnected(DEFAULT_CONNECT_TIMEOUT_MS);

    if (!options.localIP.empty())
    {
      std::string ip;
      getLocalIP(connection, ip);
      AG_LOG(INFO, "Local IP:%s", ip.c_str());
    }

    // Start sending media data
    AG_LOG(INFO, "Start sending audio & video data ...");
    // std::thread sendVideoThread(SampleSendVideoH264Task, options, videoFrameSender,
    //                             std::ref(exitFlag));
    // std::thread captureVideoThread(startCaptrueVideo, videoCallback, std::ref(exitFlag));
    std::thread sendAudioThread(SampleSendAudioTask, options, audioFrameSender, std::ref(exitFlag));
    std::thread captureAudioThread(startCaptrueAudio, std::ref(config), audioCallback, std::ref(exitFlag), std::ref(captureAudioFlag));
    playAudioThread = std::thread(startPlayAudio, DEFAULT_NUM_OF_CHANNELS, DEFAULT_SAMPLE_RATE, std::ref(exitFlag), std::ref(playAudioFlag));

    // Subcribe streams from all remote users or specific remote user
    if (options.remoteUserId.empty())
    {
      AG_LOG(INFO, "Subscribe streams from all remote users");
      connection->getLocalUser()->subscribeAllAudio();
    }
    else
    {
      connection->getLocalUser()->subscribeAudio(options.remoteUserId.c_str());
    }

    // 初始化CURL会话
    curl = curl_easy_init();
    if (curl)
    {
      string url = "https://api.sd-rtn.com/cn/api/conversational-ai-agent/v2/projects/" + string(config.app_id) + "/join";
      // 设置URL
      curl_easy_setopt(curl, CURLOPT_URL, url.c_str());

      // 设置POST请求类型
      curl_easy_setopt(curl, CURLOPT_POST, 1L);

      // 设置POST参数，这里使用一个结构体数组模拟JSON数据，实际应用中可以根据需要修改为具体的字符串格式
      struct curl_slist *headers = NULL;
      headers = curl_slist_append(headers, "Content-Type: application/json"); // 设置头部信息
      headers = curl_slist_append(headers, string("Authorization: Basic " + string(config.authorization)).c_str());
      curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers); // 应用头部信息

      // 设置POST参数的JSON字符串
      std::string postData = "{\"name\": \"" + options.channelId +
                             "\",\"properties\": {" +
                             "\"channel\":\"" + options.channelId + "\"," +
                             R"(
      "agent_rtc_uid": "0",
      "remote_rtc_uids": [
        "*"
      ],
      "enable_string_uid": true,
      "idle_timeout": 60,
      "llm": {
        "url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
        "api_key": "93902024-64db-4e5c-b050-41d3da0e5765",
        "max_history": 5,
        "system_messages": [
          {
            "role": "system",
            "content": "你的名字叫GO Mate,是由广汽集团开发的智能人形机器人"
          }
        ],
        "params": {
          "model": "doubao-1-5-lite-32k-250115",
          "max_token": 1024
        },
        "greeting_message": "你好呀，有什么可以帮您？",
        "failure_message": "我出错了，请稍等！"
      },
      "asr": {
        "language": "zh-CN"
      },
      "vad": {
        "interrupt_duration_ms": 300,
        "prefix_padding_ms": 300,
        "silence_duration_ms": 480,
        "threshold": 0.5
      },
      "tts": {
        "vendor": "bytedance",
        "params": {
          "token": "j2ncoUOAg7y9E91LWgBnJqc-bNJfuWi4",
          "app_id": "4331214271",
          "cluster": "volcano_tts",
          "voice_type": "BV002_streaming",
          "speed_ratio": 1,
          "volume_ratio": 3,
          "pitch_ratio": 1,
          "emotion": "happy"
        }
      },
      "parameters": {
        "transcript": {
          "enable": true,
          "protocol_version": "v2",
          "enable_words": false,
          "redundant": false
        },
        "enable_metrics": true,
        "audio_scenario": "default",
        "enable_dump": true
      },
      "token": ")" + options.appId +
                             "\"," +
                             "\"advanced_features\": {" +
                             "\"enable_aivad\": true" +
                             "}" +
                             "}" +
                             "}";
      curl_easy_setopt(curl, CURLOPT_POSTFIELDS, postData.c_str()); // 设置POST字段数据
      AG_LOG(INFO, "json:%s", postData.c_str());
      curl_easy_setopt(curl, CURLOPT_POSTFIELDSIZE, postData.length() + 1); // 使用字符串的实际长度

      // 设置回调函数，用于接收返回的数据
      curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
      curl_easy_setopt(curl, CURLOPT_WRITEDATA, &readBuffer); // 将返回的数据传递给readBuffer

      // 执行请求并获取结果
      res = curl_easy_perform(curl);
      if (res != CURLE_OK)
      {
        fprintf(stderr, "curl_easy_perform() failed: %s\n", curl_easy_strerror(res));
        // publishMessage(mosq, "网络不通");
      }
      else
      {
        std::cout << "Response: " << readBuffer << std::endl; // 输出返回的数据
        json j = json::parse(readBuffer);
        if (!j.contains("agent_id"))
        {
          std::exit(0);
        }
        agent_id = j["agent_id"];
        // std::string status = j["status"];
        // if (status.compare("IDLE"))
        // {
        //   status = "空闲状态";
        // }
        // else if (status.compare("STARTING"))
        // {
        //   status = "正在启动";
        // }
        // else if (status.compare("RUNNING"))
        // {
        //   status = "正在运行";
        // }
        // else if (status.compare("STOPPING"))
        // {
        //   status = "正在停止";
        // }
        // else if (status.compare("STOPPED"))
        // {
        //   status = "已退出";
        // }
        // else if (status.compare("RECOVERING"))
        // {
        //   status = "正在恢复";
        // }
        // else if (status.compare("FAILED"))
        // {
        //   status = "执行失败";
        // }
        // publishMessage(mosq, status.c_str());
      }
      // 清理头部信息列表和CURL会话
      curl_slist_free_all(headers); // 释放头部信息列表内存
      curl_easy_cleanup(curl);      // 清理CURL会话资源
    }

    // captureVideoThread.join();
    captureAudioThread.join();
    playAudioThread.join();
    // sendVideoThread.join();
    sendAudioThread.join();

    // 初始化CURL会话
    curl = curl_easy_init();
    if (curl)
    {
      string url = "https://api.agora.io/cn/api/conversational-ai-agent/v2/projects/" + string(config.app_id) + "/agents/" + string(agent_id) + "/leave";
      // 设置URL
      curl_easy_setopt(curl, CURLOPT_URL, url.c_str());

      // 设置POST请求类型
      curl_easy_setopt(curl, CURLOPT_POST, 1L);

      // 设置POST参数，这里使用一个结构体数组模拟JSON数据，实际应用中可以根据需要修改为具体的字符串格式
      struct curl_slist *headers = NULL;
      headers = curl_slist_append(headers, "Content-Type: application/json"); // 设置头部信息
      headers = curl_slist_append(headers, string("Authorization: Basic " + string(config.authorization)).c_str());
      curl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers); // 应用头部信息

      curl_easy_setopt(curl, CURLOPT_POSTFIELDS, NULL); // 设置POST字段数据
      curl_easy_setopt(curl, CURLOPT_POSTFIELDSIZE, 0); // 使用字符串的实际长度

      // 设置回调函数，用于接收返回的数据
      curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, WriteCallback);
      curl_easy_setopt(curl, CURLOPT_WRITEDATA, &readBuffer); // 将返回的数据传递给readBuffer
      // 执行请求并获取结果
      res = curl_easy_perform(curl);
      // if (res != CURLE_OK)
      // {
      //   fprintf(stderr, "curl_easy_perform() failed: %s\n", curl_easy_strerror(res));
      // }
      // else
      // {
      //   std::cout << "Response: " << readBuffer << std::endl; // 输出返回的数据
      // }

      curl_slist_free_all(headers); // 释放头部信息列表内存
      curl_easy_cleanup(curl);      // 清理CURL会话资源
    }

    // 释放资源
    // Unpublish audio & video track
    connection->getLocalUser()->unpublishAudio(customAudioTrack);
    connection->getLocalUser()->unpublishVideo(customVideoTrack);

    localUserObserver->unsetAudioFrameObserver();

    // Unregister connection observer
    connection->unregisterObserver(connObserver.get());

    // Unregister network observer
    connection->unregisterNetworkObserver(connObserver.get());

    // Disconnect from Agora channel
    if (connection->disconnect())
    {
      AG_LOG(ERROR, "Failed to disconnect from Agora channel!");
      return -1;
    }
    AG_LOG(INFO, "Disconnected from Agora channel successfully");

    // Destroy Agora connection and related resources
    connObserver.reset();
    localUserObserver.reset();
    audioFrameSender = nullptr;
    videoFrameSender = nullptr;
    customAudioTrack = nullptr;
    customVideoTrack = nullptr;
    factory = nullptr;
    connection = nullptr;
    // Destroy Agora Service
    service->release();
    service = nullptr;

    // mqtt release
    mosquitto_loop_stop(mosq, true);
    mosquitto_destroy(mosq);
    mosquitto_lib_cleanup();
  }
  catch (const std::exception &e)
  {
    std::cerr << "标准异常: " << e.what() << std::endl;
  }
  catch (...)
  {
    std::cerr << "未知异常" << std::endl;
  }

  return 0;
}

// 发布消息
void publishMessage(mosquitto *mosq, const char *message)
{
  const char *topic = "ai/conversation";

  int qos = 1;         // 服务质量等级（0, 1, 或 2）
  bool retain = false; // 是否保留消息
  // 发布启动失败消息
  int ret = mosquitto_publish(mosq, nullptr, topic, strlen(message), message, qos, retain);
  if (ret != MOSQ_ERR_SUCCESS)
  {
    std::cerr << "Error: Failed to publish message." << std::endl;
  }
  else
  {
    std::cout << "Message published successfully." << std::endl;
  }
}
